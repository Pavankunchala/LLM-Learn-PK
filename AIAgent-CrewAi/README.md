First, install Python and pipenv


```
pip install crewai
pip install crewai_tools
```

Step 4: Install Ollama for LLM
Ollama is a lightweight LLM server. Follow the instructions below:

Download and install Ollama from https://ollama.com/download.
Start the Ollama server:
```
ollama serve
```
Pull the required model (mistral-nemo) or choose another lighter model:
```
ollama pull mistral-nemo
```


